# Quick Start

## 1. Environment Setting
The environment configuration follows https://github.com/fzh0917/STMTrack.

Prepare Anaconda, CUDA and the corresponding toolkits. CUDA version required: 10.0+
Create a new conda environment and activate it.
```python
  conda create -n MMFNet python=3.7 -y
  conda activate MMFNet
```
Install pytorch and torchvision.
```python
  conda install pytorch==1.4.0 torchvision==0.5.0 cudatoolkit=10.0 -c pytorch
  # pytorch v1.5.0, v1.6.0, or higher should also be OK.
```
Install other required packages.
```python
  pip install -r requirements.txt
```
## 2. Dataset
+ The hyperspectral videos datasets are from "https://www.hsitracking.com/".
+ The Material View is generated by the paper of "Material Based Object Tracking in Hyperspectral Videos".

## 3. Train
(a). Download pretrained model in 
    - https://pan.baidu.com/s/1vBmGFoQ4MRTUeLE3o7pteg 
    - Access code: 1234 
(b). Change the path of training data in videoanalyst/evaluation/.
(c). Run: train.sh

## 4. Test
(a). Download testing model in 
    - https://pan.baidu.com/s/15YdmJRvagPzKcUNWBloiHA 
    - Access code: 1234
(b). Run: test.sh

## 5. Cite
```
  @ARTICLE{10438474,
  author={Li, Zhuanfeng and Xiong, Fengchao and Zhou, Jun and Lu, Jianfeng and Zhao, Zhuang and Qian, Yuntao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Material-Guided Multiview Fusion Network for Hyperspectral Object Tracking}, 
  year={2024},
  volume={62},
  number={},
  pages={1-15},
  keywords={Feature extraction;Hyperspectral imaging;Target tracking;Videos;Object tracking;Visualization;Spatial resolution;Hyperspectral object tracking;hyperspectral unmixing;multihead attention;multiview fusion},
  doi={10.1109/TGRS.2024.3366536}}
```

## 6. Concat
* lizhuanfeng@njust.edu.cn
If you have any questions, just create issues or email me:smile:.
